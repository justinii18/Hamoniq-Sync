//
//  AudioDecoder.swift
//  HarmoniqSyncKit
//
//  AVFoundation-based audio decoding for sync engine
//

import Foundation
import AVFoundation
import Accelerate

public class AudioDecoder {
    
    // MARK: - Types
    
    public struct AudioData {
        public let samples: [Float]
        public let sampleRate: Double
        public let duration: TimeInterval
        public let channels: Int
        
        public var isValid: Bool {
            return !samples.isEmpty && sampleRate > 0 && duration > 0
        }
    }
    
    public enum AudioDecoderError: LocalizedError {
        case invalidURL
        case unsupportedFormat
        case decodingFailed(String)
        case insufficientData
        case memoryAllocationFailed
        
        public var errorDescription: String? {
            switch self {
            case .invalidURL:
                return "Invalid audio file URL"
            case .unsupportedFormat:
                return "Unsupported audio format"
            case .decodingFailed(let reason):
                return "Audio decoding failed: \(reason)"
            case .insufficientData:
                return "Insufficient audio data for processing"
            case .memoryAllocationFailed:
                return "Failed to allocate memory for audio data"
            }
        }
    }
    
    // MARK: - Configuration
    
    public struct DecodingConfig: Sendable {
        public let targetSampleRate: Double
        public let monoMix: Bool
        public let normalize: Bool
        public let maxDurationSeconds: TimeInterval?
        
        public init(
            targetSampleRate: Double = 44100.0,
            monoMix: Bool = true,
            normalize: Bool = true,
            maxDurationSeconds: TimeInterval? = nil
        ) {
            self.targetSampleRate = targetSampleRate
            self.monoMix = monoMix
            self.normalize = normalize
            self.maxDurationSeconds = maxDurationSeconds
        }
        
        public static let standard = DecodingConfig()
        public static let highQuality = DecodingConfig(targetSampleRate: 48000.0)
        public static let fast = DecodingConfig(targetSampleRate: 22050.0)
    }
    
    // MARK: - Public API
    
    /// Decode audio file to PCM samples
    /// - Parameters:
    ///   - url: Audio file URL
    ///   - config: Decoding configuration
    /// - Returns: Decoded audio data
    /// - Throws: AudioDecoderError on failure
    public static func decode(url: URL, config: DecodingConfig = .standard) async throws -> AudioData {
        return try await withCheckedThrowingContinuation { continuation in
            DispatchQueue.global(qos: .userInitiated).async {
                do {
                    let audioData = try decodeSync(url: url, config: config)
                    continuation.resume(returning: audioData)
                } catch {
                    continuation.resume(throwing: error)
                }
            }
        }
    }
    
    /// Synchronous decode (for use in C++ bridge)
    public static func decodeSync(url: URL, config: DecodingConfig = .standard) throws -> AudioData {
        // Validate URL
        guard url.isFileURL || url.scheme != nil else {
            throw AudioDecoderError.invalidURL
        }
        
        // Create AVAudioFile
        let audioFile: AVAudioFile
        do {
            audioFile = try AVAudioFile(forReading: url)
        } catch {
            throw AudioDecoderError.decodingFailed("Failed to open audio file: \(error.localizedDescription)")
        }
        
        // Get file format information
        let inputFormat = audioFile.processingFormat
        let frameCount = AVAudioFrameCount(audioFile.length)
        
        // Validate format
        guard inputFormat.sampleRate > 0 && inputFormat.channelCount > 0 else {
            throw AudioDecoderError.unsupportedFormat
        }
        
        // Calculate target frame count
        let maxFrames: AVAudioFrameCount
        if let maxDuration = config.maxDurationSeconds {
            maxFrames = min(frameCount, AVAudioFrameCount(maxDuration * inputFormat.sampleRate))
        } else {
            maxFrames = frameCount
        }
        
        // Create output format
        let outputFormat = AVAudioFormat(
            standardFormatWithSampleRate: config.targetSampleRate,
            channels: config.monoMix ? 1 : inputFormat.channelCount
        )!
        
        // Create audio buffer
        guard let audioBuffer = AVAudioPCMBuffer(pcmFormat: inputFormat, frameCapacity: maxFrames) else {
            throw AudioDecoderError.memoryAllocationFailed
        }
        
        // Read audio data
        do {
            try audioFile.read(into: audioBuffer, frameCount: maxFrames)
        } catch {
            throw AudioDecoderError.decodingFailed("Failed to read audio data: \(error.localizedDescription)")
        }
        
        // Convert to target format if needed
        let processedBuffer: AVAudioPCMBuffer
        if inputFormat.sampleRate != config.targetSampleRate || 
           inputFormat.channelCount != outputFormat.channelCount {
            processedBuffer = try convertFormat(buffer: audioBuffer, targetFormat: outputFormat)
        } else {
            processedBuffer = audioBuffer
        }
        
        // Extract samples
        var samples = try extractSamples(from: processedBuffer, monoMix: config.monoMix)
        
        // Normalize if requested
        if config.normalize {
            normalizeSamples(&samples)
        }
        
        // Validate result
        guard !samples.isEmpty else {
            throw AudioDecoderError.insufficientData
        }
        
        return AudioData(
            samples: samples,
            sampleRate: config.targetSampleRate,
            duration: Double(samples.count) / config.targetSampleRate,
            channels: config.monoMix ? 1 : Int(inputFormat.channelCount)
        )
    }
    
    /// Decode audio segment with start time and duration
    public static func decode(
        url: URL,
        startTime: TimeInterval,
        duration: TimeInterval,
        config: DecodingConfig = .standard
    ) async throws -> AudioData {
        return try await withCheckedThrowingContinuation { continuation in
            DispatchQueue.global(qos: .userInitiated).async {
                do {
                    let audioFile = try AVAudioFile(forReading: url)
                    let inputFormat = audioFile.processingFormat
                    
                    let startFrame = AVAudioFramePosition(startTime * inputFormat.sampleRate)
                    let _ = AVAudioFrameCount(duration * inputFormat.sampleRate)
                    
                    // Seek to start position
                    audioFile.framePosition = startFrame
                    
                    // Create modified config for segment
                    let segmentConfig = DecodingConfig(
                        targetSampleRate: config.targetSampleRate,
                        monoMix: config.monoMix,
                        normalize: config.normalize,
                        maxDurationSeconds: duration
                    )
                    
                    let audioData = try decodeSync(url: url, config: segmentConfig)
                    continuation.resume(returning: audioData)
                } catch {
                    continuation.resume(throwing: error)
                }
            }
        }
    }
    
    // MARK: - Private Implementation
    
    private static func convertFormat(
        buffer: AVAudioPCMBuffer,
        targetFormat: AVAudioFormat
    ) throws -> AVAudioPCMBuffer {
        
        guard let converter = AVAudioConverter(from: buffer.format, to: targetFormat) else {
            throw AudioDecoderError.unsupportedFormat
        }
        
        let outputFrameCount = AVAudioFrameCount(
            Double(buffer.frameLength) * targetFormat.sampleRate / buffer.format.sampleRate
        )
        
        guard let outputBuffer = AVAudioPCMBuffer(
            pcmFormat: targetFormat,
            frameCapacity: outputFrameCount
        ) else {
            throw AudioDecoderError.memoryAllocationFailed
        }
        
        var error: NSError?
        let status = converter.convert(to: outputBuffer, error: &error) { _, outStatus in
            outStatus.pointee = .haveData
            return buffer
        }
        
        guard status != .error else {
            throw AudioDecoderError.decodingFailed(
                error?.localizedDescription ?? "Format conversion failed"
            )
        }
        
        return outputBuffer
    }
    
    private static func extractSamples(
        from buffer: AVAudioPCMBuffer,
        monoMix: Bool
    ) throws -> [Float] {
        
        guard let floatChannelData = buffer.floatChannelData else {
            throw AudioDecoderError.decodingFailed("Buffer contains no float data")
        }
        
        let frameCount = Int(buffer.frameLength)
        let channelCount = Int(buffer.format.channelCount)
        
        if monoMix && channelCount > 1 {
            // Mix multiple channels to mono
            var monoSamples = [Float](repeating: 0.0, count: frameCount)
            
            for frame in 0..<frameCount {
                var sum: Float = 0.0
                for channel in 0..<channelCount {
                    sum += floatChannelData[channel][frame]
                }
                monoSamples[frame] = sum / Float(channelCount)
            }
            
            return monoSamples
        } else {
            // Use first channel or interleaved data
            let samples = Array(UnsafeBufferPointer(
                start: floatChannelData[0],
                count: frameCount
            ))
            return samples
        }
    }
    
    private static func normalizeSamples(_ samples: inout [Float]) {
        guard !samples.isEmpty else { return }
        
        // Find peak amplitude
        var peak: Float = 0.0
        vDSP_maxmgv(samples, 1, &peak, vDSP_Length(samples.count))
        
        guard peak > 0.0 else { return }
        
        // Normalize to 0.95 peak to avoid clipping
        var scale = 0.95 / peak
        vDSP_vsmul(samples, 1, &scale, &samples, 1, vDSP_Length(samples.count))
    }
}

// MARK: - Utility Extensions

extension AudioDecoder.AudioData {
    /// Get audio samples as a pointer for C++ bridge
    public func withUnsafeFloatPointer<T>(_ body: (UnsafePointer<Float>) throws -> T) rethrows -> T {
        return try samples.withUnsafeBufferPointer { buffer in
            try body(buffer.baseAddress!)
        }
    }
    
    /// Create audio data from existing samples (for testing)
    public static func mock(
        samples: [Float],
        sampleRate: Double = 44100.0
    ) -> AudioDecoder.AudioData {
        return AudioDecoder.AudioData(
            samples: samples,
            sampleRate: sampleRate,
            duration: Double(samples.count) / sampleRate,
            channels: 1
        )
    }
}